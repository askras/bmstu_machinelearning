---
title: "Лекция 22: Локализация объектов на изображении"
subtitle: Машинное обучение и анализ данных
author: "Красников А. С."
date: 2025-03-20
date-modified: last-modified
institute: МГТУ им. Н.Э. Баумана
format: 
  revealjs:
    #incremental: true  
    scrollable: true
    center-title-slide: false
    # Slide TRansitions
    transition: fade
    
    width: 1920
    height: 1080
---


# Задачи обработки изображений {.center}


## **Классификация** (classification, recognition)

Выходом являются вероятности присутствия объектов интересующих классов на изображении в целом.
Подсчет количества объектов одного класса обычно не ведется.

![](./img/task-classification.jpg){fig-align="center"  .r-stretch}


## **Локализация объектов** (object detection)

Каждый объект интересующих классов выделяется прямоугольной рамкой с меткой класса, которому объект принадлежит.

![](./img/task-detection.jpg){fig-align="center"  .r-stretch}


## **Семантическая сегментация** (semantic segmentation)

Каждый пиксель помечается тем или иным классом в зависимости от того, объект какого типа он покрывает. 
Метки пикселей представителей одного класса, не различаются.

![](./img/task-semantic-segmentation.jpg){fig-align="center"  .r-stretch}


## **Инстанс-сегментация** (instance segmentation)

Каждый пиксель изображения помечается своим классом, при этом различаются выделения различных представителей одного класса. 

![](./img/task-instance-segmentation.jpg){fig-align="center"  .r-stretch}



# Основы локализация объектов {.center}

## Применение задачи локализации

:::: {.columns}

::: {.column width="60%"}
- Подсчёт участников мероприятий и пассажиропотока
- Системы безопасности: обнаружение людей и запрещённых предметов
- Логистика: контроль товаров на полках магазинов
- Автономные автомобили: локализация машин, пешеходов, дорожных знаков
- Распознавание лиц на фотографиях (видоискателе)
:::

::: {.column width="40%"}
![](./img/object-detection.jpg){fig-align="center"  .r-stretch}
:::

::::


## Простой подход к локализации

:::: {.columns}

::: {.column width="60%"}
**Алгоритм:**

1. Использование изображения-образца объекта
2. Поиск корреляции с фрагментами входного изображения
3. Масштабирование изображения для поиска объектов разного размера

**Ограничения метода:**

- Чувствительность к освещению и углу поворота
- Низкая эффективность для сложных объектов (машины разных моделей)
- Требует точного шаблона для сравнения
:::

::: {.column width="40%"}
![Сканирование изображения образцом](./img/traffic-signs.jpg)
:::

::::


# Оценка качества локализации {.center}


## Intersection-over-Union (IoU)

$$
\text{IoU} = \frac{\mid\hat{Y} \cap Y\mid}{\mid\hat{Y} \cup Y\mid},
$$
где 

- $Y$ --- множество пикселей попадающих в истинную рамку, выделяющую целевой объект,
- $\hat{Y}$ --- множество пикселей попадающих в предсказанную рамку, выделяющую целевой объект.

![](./img/IoU.png)

## Вариатны Intersection-over-Union (IoU)

- **Верно положительные** (**True Positives**): <br>
модель корректно распознала класс объекта и выделила его рамкой, сильно пересекающейся с истинной рамкой ($\text{IoU} \geqslant \alpha$^[$0 < \alpha \leqslant 1$ --- порог принятия решений]).
- **Ложно положительные** (**False Positives**):
модель выделила рамкой объект, которого на самом деле нет либо выделила присутствующий объект, но неточно ($\text{IoU} < \alpha$).
- **Ложно отрицательные** (**False Negatives**): <br>
модель не распознала реально присутствующий объект ($\hat{Y} = 0$).

- **Верно отрицательные** (**True Negatives**)^[Данный вариант не рассматривается (обычно важны только корректные/некорректные выделения объектов целевых классов)]: <br>
модель корректно не сработала на отсутствие объектов ($Y = 0$, $\hat{Y} \ne 0$).


Далее, на основе $\text{IoU}$ для конкретного класса считаются меры **Precision** и **Recall**, как в бинарной классификации.


## Ключевые метрики качества

**Precision (Точность):** доля корректных обнаружений среди всех обнаружений
$$\text{Precision} = \frac{TP}{TP + FP}$$


**Recall (Полнота):** доля найденных объектов от общего числа существующих объектов
$$\text{Recall} = \frac{TP}{TP + FN}$$

**F-мера:** гармоническое среднее Precision и Recall
$$\text{F-measure} = \frac{2 \cdot \text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}$$


## Зависимость Precision и Recall от $\alpha$

Меры Precision и Recall вычисляются для фиксированного значения порога $\alpha$. 
При изменении этого порога они будут некоторыми функциями от него:

$$\text{Precision}=\text{Precision}(\alpha)$$
$$\text{Recall}​=\text{Recall}(\alpha)$$​


::: {.callout-note collapse="true" title="Как будут изменяться Precision и Recall при увеличении $\alpha$?"}
При увеличении $\alpha$ детектор будет осторожнее выделять объекты --- только там, где он больше в них уверен.

Соответственно Precision будет увеличиваться ценой того, что Recall будет становиться ниже.
:::


## Precision-Recall Curve (График зависимости точности от полноты)

Варьируя $\alpha$ от 0 до 1, можно построить график зависимости P(R)=Precision(Recall):

:::: {.columns}

::: {.column width="60%"}
**Особенности графика:**

- Пилообразная форма из-за дискретных порогов IoU
- Сглаживание через **интерполированную точность** (interpolated precision):
$$P(R) \rightarrow \tilde{P}(R) = \max_{\tilde{R} \geq R} P(R)$$
:::

::: {.column width="40%"}
![](./img/PRCurve.png){fig-align="center"  .r-stretch}
:::

::::



## Average Precision (AP)

Варьируя $\alpha$ от 0 до 1, можно вычислить меру Average Precision (AP) 
как площадь под графиком интерполированной точности

$$\text{AP} = \int\limits_0^1 \tilde{P}(R) \, dR.$$

На практике часто:

- разбивают значения Recall на равномерно распределённые значения $R_0$, $R_1$, ..., $R_K$​ (обычно {0, 0.1, 0.2, ..., 0.9,1}) 
и вычисляют приближённую площадь:

$$\text{AP} = \sum\limits_{k=1}^K \tilde{P}(R) (R_k - R_{k-1}).$$


## Mean Average Precision (mAP) Среднее значение AP по всем классам
$$ mAP = \frac{1}{C} \sum_{c=1}^{C} AP_c$$


## Практические аспекты
**Факторы влияния:**

- Порог IoU (стандартные значения: 0.5 или 0.75)
- Количество классов
- Баланс между объектами разных размеров

**Оптимизация:**

- Увеличение Recall без существенного падения Precision
- Использование каскадных классификаторов
- Постобработка (NMS, Soft-NMS)

**Практическое применение:**

- Основная метрика для сравнения алгоритмов локализации
- Учитывает баланс между точностью и полнотой
- Стандартизированная оценка для разных датасетов (COCO, PASCAL VOC)


## Практическое применение

**Автономные автомобили:**

- локализация пешеходов: $$ P(\text{обнаружение}) \geq 0.99 $$
- Распознавание дорожных знаков в реальном времени

**Ритейл:**

- Анализ заполненности полок
- Автоматизация инвентаризации

**Безопасность:**

- Обнаружение аномалий на видеопотоке
- Системы контроля доступа


# Подавление немаксимумов {.center}


## Базовый алгоритм NMS

Алгоритм подавления немаксимумов (Non-Maximum Suppression, NMS)
 решает проблему избыточных детекций объектов^[Bodla N. et al. Soft-NMS--improving object detection with one line of code //Proceedings of the IEEE international conference on computer vision. – 2017. – С. 5561-5569.].

:::: {.columns}

::: {.column width="60%"}

- Требуется --- минимально достаточный набор всех выделений
- Основные шаги:
  1. Сортировка боксов по убыванию рейтинга IoU (confidence score)
  2. Выбор бокса с максимальной оценкой
  3. Вычисление метрики пересечения (IoU) с остальными боксами
  4. Удаление боксов с IoU выше заданного порога (threshold)
  5. Повторение шагов 2-4 пока не обработаем все боксы
- Применяе для каждого класса в отдельности.

:::

::: {.column width="40%"}
![Пример v NMS](./img/non-maximum-supression.jpg)
:::

::::

## Мягкий вариант алгоритма NMS

Базовый алгоритм подавления немаксимумов жёстко отбрасывает выделения, имеющие $\text{IoU} \geqslant \text{threshold}$ 
с выделением, имеющим более высокий рейтинг. 


:::: {.columns}

::: {.column width="60%"}

Идея: 

- оставлять все детекции, 
- для выделений, имеющих сильное пересечение с другими высокорейтинговыми выделениями, дополнительно снижать рейтинг. 
- итоговыми детекциями будут те, у которых рейтинг выше некоторого порога $\beta > 0$
- устанавливая $\beta$ достаточно низким, можно извлечь большее число объектов (ценой более частых дублированных выделений одного и того же объекта).

:::

::: {.column width="40%"}
![](./img/near-selections.jpg)
:::

::::


# Модель YOLO (You Look Only Once) {.center}

## Введение
- Одна из самых быстрых моделей для локализации объектов
- Единая нейросетевая архитектура для полного анализа изображения
- Реализует подход &laquo;один проход&raquo; (single-shot detection)

![Архитектура YOLO](./img/YOLO.png)


## Ключевые особенности архитектуры
- Последовательные сверточные слои с шагом 2 для уменьшения разрешения
- Использование &laquo;точечных&raquo; сверток 1x1 для уменьшения каналов
- Два полносвязных слоя в конце для учета глобального контекста
- Первый слой: свертка 7x7 для быстрого уменьшения разрешения


## Выходной тензор YOLO
Формат выхода: $S \times S \times (B*5 + C)$

- $S$ = размер сетки (7 в оригинале)
- $B$ = количество предсказываемых боксов на ячейку (2)
- $C$ = количество классов

![Пример выхода для S=5 и B=1](./img/YOLO-output.png)


## Компоненты предсказания
Для каждой ячейки сетки:

1. **Confidence score**: $\text{conf} = p(obj) \cdot IoU_{true}^{pred}$
2. **Координаты бокса**: (x, y, w, h)
3. **Вероятности классов**: $p(class_i|obj)$

## Функция потерь
Состоит из трех компонент:

### 1. Поиск объектов
$\lambda_{coord} \sum (1 - conf)^2$ (при наличии объекта)  
$\lambda_{noobj} \sum (0 - conf)^2$ (при отсутствии)

### 2. Классификация
$\sum (p_i(class) - \hat{p}_i(class))^2$

### 3. Точность локализации объекта
$\sum [(\hat{x}-x)^2 + (\hat{y}-y)^2 + (\sqrt{\hat{w}}-\sqrt{w})^2 + (\sqrt{\hat{h}}-\sqrt{h})^2]$

## Особенности обучения
- Объект привязывается к ячейке, содержащей его центр
- Каждый предсказатель специализируется на определенных аспектах
- Вес компоненты локализации ($\lambda_{coord}$ = 5)
- Меньший вес для &laquo;пустых&raquo; ячеек ($\lambda_{noobj}$ = 0.5)


## Преимущества и недостатки

**Плюсы:**

- Высокая скорость работы (45 FPS в оригинале)
- Простая архитектура
- Глобальный контекст анализа

**Минусы:**

- Низкая точность для мелких объектов
- Ограничение на максимум 49 объектов (при S=7)
- Проблемы с редкими классами

## Эволюция YOLO
- YOLOv2: Anchor boxes, multi-scale training
- YOLOv3: Feature pyramid networks
- YOLOv4: CSPDarknet, SAM attention
- YOLOv5: Focus layer, autoanchor
- YOLOv8: Последняя версия с SOTA результатами


## Применение
- Системы видеонаблюдения
- Автономные транспортные средства
- Медицинская диагностика
- Промышленный контроль качества
- Спортивная аналитика


## Литература

1. Redmon J. et al. ["You Only Look Once: Unified, Real-Time Object Detection"](https://arxiv.org/abs/1506.02640) (CVPR 2016)
2. Официальный сайт: [pjreddie.com/darknet/yolo/](https://pjreddie.com/darknet/yolo/)


# Модель SSD (Single Shot Detector) {.center}


## Архитектура
- Решает проблемы YOLO: низкое качество локализации мелких объектов и ограничение на 49 детекций
- Использует **многоуровневые признаки**:
  - Глубокие слои: локализация крупных объектов
  - Ранние слои: локализация мелких объектов
- Основана на предобученной VGG-16
- Модуль подавления не-максимумов (NMS) для фильтрации дублирующих детекций

![*Сравнение SSD (сверху) и YOLO (снизу)](./img/SSD-architecture.png)


## Ключевые особенности
- **Шаблонные рамки (Anchor Boxes)**:

  - Несколько предопределённых форм/размеров на позицию
  - 3 варианта: большая/средняя/малая + квадратные/вытянутые

- **Прогнозирование для каждой позиции**:

  - $K(C+4)$ значений:
    - $K$ anchor boxes
    - $C$ вероятностей классов
    - 4 координаты: $(\Delta x, \Delta y, \Delta w, \Delta h)$

![Пример локализации](./img/SSD-anchor-boxes-9c120ac320ccb6771b9bb3c35b393b87.jpg)
*локализация объектов через anchor boxes. Источник: Springer*

---

## Механизм прогнозирования
1. Для каждой позиции на карте признаков:
   - Генерируются K anchor boxes
   - Предсказываются:
     - Смещения относительно anchor box
     - Вероятности классов
2. Пример для 3 anchor boxes:
   - Координаты: $(x_{center}, y_{center}, w, h)$
   - Преобразование: 
     $$
     \begin{cases}
     x = x_{anchor} + w_{anchor} \cdot \Delta x \\
     y = y_{anchor} + h_{anchor} \cdot \Delta y \\
     w = w_{anchor} \cdot e^{\Delta w} \\
     h = h_{anchor} \cdot e^{\Delta h}
     \end{cases}
     $$

## Функция потерь
Состоит из двух компонент:

1. **Локализация**:

   - Smooth $L_1$ loss для смещений
   - Только для позитивных примеров (IoU > 0.5)

2. **Классификация**:

   - Кросс-энтропия
   - Hard Negative Mining: баланс позитивных/негативных примеров

## Преимущества и инновации

**Преимущества перед YOLO**:

- Выше точность для мелких объектов (+12.7% mAP)
- Больше детекций: до 8732 предсказаний
- Быстрее обучение (2-3 дня на 8 GPU)

**Ключевые инновации**:

- Многоуровневая локализация
- Anchor boxes с относительными смещениями
- Эффективная стратегия выборки негативов

## Применение
- Системы реального времени (58 FPS на Titan X)
- Видеонаблюдение: подсчёт людей/транспорта
- Медицинская диагностика: обнаружение патологий
- Автономные роботы: навигация и obstacle avoidance


## Литература
1. Liu W. et al. ["SSD: Single Shot MultiBox Detector"](https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2) (ECCV 2016)
2. Официальная документация: [DeepMachineLearning.ru/SSD](https://deepmachinelearning.ru/docs/Neural-networks/Object-detection/SSD)
