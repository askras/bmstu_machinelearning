---
jupyter:
  jupytext:
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.16.4
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

# Высокопроизводительные Pandas: eval() и query()


Мощь стека PyData основана на способности NumPy и Pandas переносить базовые операции в C с помощью интуитивно понятного синтаксиса: примерами являются векторизованные/транслируемые операции в NumPy и операции группировки в Pandas.
Несмотря на то, что эти абстракции весьма производительны и эффективно работают для многих распространенных сценариев использования, они зачастую требуют создания временных вспомогательных объектов, что приводит к чрезмерным накладным расходам как процессорного времени, так и оперативной памяти.

Начиная с версии 0.13 (выпущенной в январе 2014 г.), Pandas включает в себя несколько инструментов, которые позволяют напрямую получать доступ к операциям на скорости C без затратного выделения промежуточных массивов.
Это функции `eval()` и `query()`, которые используют пакет [Numexpr](https://github.com/pydata/numexpr).


## Составные выражения

NumPy и Pandas поддерживают быстрые векторизованные операции, например, при сложении элементов двух массивов:

```python jupyter={"outputs_hidden": false}
import numpy as np
rng = np.random.RandomState(42)
x = rng.rand(1000000)
y = rng.rand(1000000)
%timeit x + y
```

Это намного быстрее, чем выполнять сложение с помощью цикла или спискового включения Python:

```python jupyter={"outputs_hidden": false}
%timeit np.fromiter((xi + yi for xi, yi in zip(x, y)), dtype=x.dtype, count=len(x))
```

Однако эта абстракция оказывается менее эффективной при вычислении составных выражений.
Например, рассмотрим следующее выражение:

```python
mask = (x > 0.5) & (y < 0.5)
```

Поскольку NumPy вычисляет каждое подвыражение, это примерно эквивалентно следующему:

```python
tmp1 = (x > 0.5)
tmp2 = (y < 0.5)
mask = tmp1 & tmp2
```

Другими словами, *для каждого промежуточного шага явным образом выделяется оперативная память*. Если массивы `x` и `y` очень большие, это может привести к значительным накладным расходам памяти и времени.
Библиотека Numexpr дает вам возможность вычислять этот тип составных выражений поэлементно, без необходимости выделения памяти под промежуточные массивы целиком.
В [Документации Numexpr](https://github.com/pydata/numexpr) приведено больше подробностей, но на данный момент достаточно сказать, что библиотека принимает *строку*, содержащую выражение в стиле NumPy, которое необходимо вычислить:

```python jupyter={"outputs_hidden": false}
import numexpr
mask_numexpr = numexpr.evaluate('(x > 0.5) & (y < 0.5)')
np.allclose(mask, mask_numexpr)
```

Преимущество заключается в том, что Numexpr вычисляет выражение таким образом, что не использует полноразмерные временные массивы, и поэтому может быть намного эффективнее NumPy, особенно для больших массивов.
Инструменты `eval()` и `query()` библиотеки Pandas концептуально схожи и используют пакет Numexpr.


## Использование `pandas.eval()` для эффективных операций

Функция `eval()` в Pandas использует строковые выражения для эффективного выполнения операций с использованием `DataFrame`.
Например, рассмотрим следующие `DataFrame`:

```python jupyter={"outputs_hidden": false}
import pandas as pd
nrows, ncols = 100000, 100
rng = np.random.RandomState(42)
df1, df2, df3, df4 = (pd.DataFrame(rng.rand(nrows, ncols))
                      for i in range(4))
```

Чтобы вычислить сумму всех четырех `DataFrame`, используя типичный подход Pandas, можно просто записать:

```python jupyter={"outputs_hidden": false}
%timeit df1 + df2 + df3 + df4
```

Тот же результат можно вычислить с помощью `pd.eval`, задав выражение в виде строки:

```python jupyter={"outputs_hidden": false}
%timeit pd.eval('df1 + df2 + df3 + df4')
```

Версия этого выражения с использованием функции `eval()` примерно на 50% быстрее (и использует гораздо меньше памяти), при этом давая тот же результат:

```python jupyter={"outputs_hidden": false}
np.allclose(df1 + df2 + df3 + df4,
            pd.eval('df1 + df2 + df3 + df4'))
```

### Операции, поддерживаемые `pd.eval()`

Начиная с версии Pandas v0.16, `pd.eval()` поддерживает широкий спектр операций.
Для демонстрации будем использовать следующие целочисленные `DataFrame`:

```python
df1, df2, df3, df4, df5 = (pd.DataFrame(rng.randint(0, 1000, (100, 3)))
                           for i in range(5))
```

#### Арифметические операторы
`pd.eval()` поддерживает все арифметические операторы. Например:

```python jupyter={"outputs_hidden": false}
result1 = -df1 * df2 / (df3 + df4) - df5
result2 = pd.eval('-df1 * df2 / (df3 + df4) - df5')
np.allclose(result1, result2)
```

#### Операторы сравнения
`pd.eval()` поддерживает все операторы сравнения, включая цепочки выражений:

```python jupyter={"outputs_hidden": false}
result1 = (df1 < df2) & (df2 <= df3) & (df3 != df4)
result2 = pd.eval('df1 < df2 <= df3 != df4')
np.allclose(result1, result2)
```

#### Побитовые операторы
`pd.eval()` поддерживает побитовые операторы `&` и `|`:

```python jupyter={"outputs_hidden": false}
result1 = (df1 < 0.5) & (df2 < 0.5) | (df3 < df4)
result2 = pd.eval('(df1 < 0.5) & (df2 < 0.5) | (df3 < df4)')
np.allclose(result1, result2)
```

Кроме того, она допускает использование литеральных `and`` и `or` в логических выражениях:

```python jupyter={"outputs_hidden": false}
result3 = pd.eval('(df1 < 0.5) and (df2 < 0.5) or (df3 < df4)')
np.allclose(result1, result3)
```

#### Атрибуты и индексы объектов

`pd.eval()` поддерживает доступ к атрибутам объектов через синтаксис `obj.attr` и индексам через синтаксис `obj[index]`:

```python jupyter={"outputs_hidden": false}
result1 = df2.T[0] + df3.iloc[1]
result2 = pd.eval('df2.T[0] + df3.iloc[1]')
np.allclose(result1, result2)
```

## Использование метода `DataFrame.eval()` для операций со столбцами

У объектов DataFrame существует метод `eval()`, работающий схожим образом с высокоуровневой функцией `pd.eval()` из библиотеки Pandas. 
Преимущество метода `eval()` заключается в возможности ссылаться на столбцы по имени. 
В качестве примера будем использовать следующий маркированный массив:

```python jupyter={"outputs_hidden": false}
df = pd.DataFrame(rng.rand(1000, 3), columns=['A', 'B', 'C'])
df.head()
```

Используя `pd.eval()` можно выполнять операции со стоблцами следующим образом:

```python jupyter={"outputs_hidden": false}
result1 = (df['A'] + df['B']) / (df['C'] - 1)
result2 = pd.eval("(df.A + df.B) / (df.C - 1)")
np.allclose(result1, result2)
```

Метод `DataFrame.eval()` позволяет описывать выражения для операций со столбцами более лаконично:

```python jupyter={"outputs_hidden": false}
result3 = df.eval('(A + B) / (C - 1)')
np.allclose(result1, result3)
```

Обратите внимание, что имена столбцов в вычисляемом выражении рассматриваются как переменные, что и приводит к нужному результату.


### Присваивание в методе DataFrame.eval()

В дополнение к только что рассмотренным параметрам, `DataFrame.eval()` также позволяет выполнять присваивание значения любому столбцу.
Воспользуемся `DataFrame` из предыдущего примера:

```python jupyter={"outputs_hidden": false}
df.head()
```

Используем `df.eval()`, чтобы создать новый столбец `'D'` и присвоить ему значение, вычисленное на основе других столбцов:

```python jupyter={"outputs_hidden": false}
df.eval('D = (A + B) / C', inplace=True)
df.head()
```

Таким же образом можно изменить любой существующий столбец:

```python jupyter={"outputs_hidden": false}
df.eval('D = (A - B) / C', inplace=True)
df.head()
```

### Локальные переменные в методе DataFrame.eval()

Метод `DataFrame.eval()` поддерживает дополнительный синтаксис, позволяющий ему работать с локальными переменными Python:

```python jupyter={"outputs_hidden": false}
column_mean = df.mean(1)
result1 = df['A'] + column_mean
result2 = df.eval('A + @column_mean')
np.allclose(result1, result2)
```

Символ `@` здесь обозначает *имя переменной*, а не *имя столбца*, и позволяет эффективно вычислять выражения с использованием двух пространств имен: пространство имен столбцов и пространство имен объектов Python.
Обратите внимание, что символ `@` поддерживается только *методом* `DataFrame.eval()`, но не *функцией* `pandas.eval()`, поскольку функция `pandas.eval()` имеет доступ только к одному пространству имен (Python).


## Метод DataFrame.query()

`DataFrame` имеет еще один метод, снованный на вычислении строк,, называемый методом `query()`.
Рассмотрим следующее:

```python jupyter={"outputs_hidden": false}
result1 = df[(df.A < 0.5) & (df.B < 0.5)]
result2 = pd.eval('df[(df.A < 0.5) & (df.B < 0.5)]')
np.allclose(result1, result2)
```

Как и в примере, использованном в обсуждении `DataFrame.eval()`, это выражение, включает столбцы `DataFrame`.
Однако его невозможно выразить с помощью синтаксиса `DataFrame.eval()`!
Вместо него для подобных операций фильтрации можно использовать метод `query()`:

```python jupyter={"outputs_hidden": false}
result2 = df.query('A < 0.5 and B < 0.5')
np.allclose(result1, result2)
```

Помимо того, что это более эффективное вычисление, по сравнению с маскирующим выражением, его гораздо легче читать и понимать.
Обратите внимание, что метод ``query()`` также принимает флаг ``@`` для обозначения локальных переменных:

```python jupyter={"outputs_hidden": false}
Cmean = df['C'].mean()
result1 = df[(df.A < Cmean) & (df.B < Cmean)]
result2 = df.query('A < @Cmean and B < @Cmean')
np.allclose(result1, result2)
```

## Производительность: когда следует использовать эти функции

При рассмотрении вопроса об использовании этих функций необходимо учитывать два фактора: *время вычислений* и *использование памяти*.
Предсказать объем используемой памяти довольно просто.
Как уже упоминалось, каждое составное выражение, включающее массивы NumPy или `DataFrame` Pandas, приведет к неявному созданию временных массивов:
Например, следующее выражение:

```python
x = df[(df.A < 0.5) & (df.B < 0.5)]
```

Примерно эквивалентно этому:

```python jupyter={"outputs_hidden": false}
tmp1 = df.A < 0.5
tmp2 = df.B < 0.5
tmp3 = tmp1 & tmp2
x = df[tmp3]
```

Если размер временных `DataFrame` значителен по сравнению с доступной системной памятью (обычно несколько гигабайт), то хорошей идеей будет использовать выражение `eval()` или `query()`.
Проверить приблизительный размер массива в байтах можно используя команду:

```python jupyter={"outputs_hidden": false}
df.values.nbytes
```

С точки зрения производительности `eval()` будет работать быстрее, если не заполняется вся системная памятьу.
Основную роль играет отношение размера временных объектов DataFrame по сравнению с размером L1 или L2 кэша процессора в системе (он в среднем составляет несколько мегабайт). 
eval() позволяет избежать потенциально медленного перемещения значений между различными кэшами памяти в том случае, когда это отношение намного больше 1. 
На практике различие в скорости вычислений между традиционными методами и методом `eval`/
`query` обычно довольно незначительно.
Традиционный метод обычно работает даже быстрее для маленьких массивов! 
Преимущество метода `eval`/`query` заключается в экономии оперативной памяти и иногда &mdash; в более понятном синтаксисе.


Для получения дополнительной информации о `eval()` и `query()` можно обратиться к документации Pandas.
В частности, можно задавать для работы этих запросов различные синтаксические
анализаторы и механизмы. 
Подробности &mdash; в разделе [Enhancing Performance](http://pandas.pydata.org/pandas-docs/dev/user_guide/enhancingperf.html)
